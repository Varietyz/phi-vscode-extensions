{
  "framework_templates": {
    "full_pipeline": {
      "trigger": ["Î¦ =", "phi =", "pipeline", "framework"],
      "priority": 8,
      "content": "Î¦ = {\n    [SYSTEM_OPTIMIZER_MODULE]\n    Î¨.optimizer = {\n        Ï.filter: {\n            dup.patterns: /(\\{[^}]*\\})\\s*\\1+/g,\n            rep.symbols: /(âˆ€|âˆƒ|âˆˆ|âˆ§|âˆ¨)\\s+\\1+/g,\n            overconfidence.patterns: /(guarantee|certain|always|never|complete|perfect|absolute)/gi\n        },\n        Î½.normalizer: {\n            entity.std: \"entity\",\n            attr.std: \"attr\",\n            val.std: \"val\",\n            rel.std: \"rel\"\n        },\n        Î±.validator: {\n            conflicts: {\"âˆƒ\": \"âˆƒ\", \"Â¬\": \"Â¬\", \"â†’\": \"â†’\"},\n            overconfidence_claims: {\n                pattern: /(guarantee|certain|always|never)/gi,\n                action: \"REPLACE_WITH_PROBABILISTIC_LANGUAGE\",\n                flag: \"âš (overconfidence_claim_requires_qualification)\"\n            }\n        }\n    },\n    [â„œ.FORENSICS]\n    â„œ.forensics = {\n        causal.chain.model = âˆ€ evidence.artifact â†’ backward.trace(effect â†’ cause.hypothesis) âˆ§ âš (gaps.possible),\n        triangulation.loop = âˆ€ hypothesis â†’ multiple.validation.vectors âˆ§ ğŸ§ª(verification.requirement),\n        anomaly.detection = statistical.baseline â†’ deviation.identification âˆ§ ğŸ”(pattern.recognition)\n    },\n    [Î .COMPILE]\n    Î .compile = âˆ€ input.text â†’ symbolic.phicode.probabilistic âŸ¹ {\n        Î¾.domain = context.classification âˆ§ challenge.detect âˆ§ âš ,\n        Îµ.entity = identification â†’ extraction âˆ§ ğŸŒ€.analyze âˆ§ ğŸ”,\n        Ï€.pipeline = adaptive.sequence.best_effort âˆ§ uncertainty.explicit\n    }\n}",
      "description": "Strong foundation"
    },
    "basic_pipeline": {
      "trigger": ["basic", "simple", "starter"],
      "priority": 8,
      "content": "Î¦ = {\n    Î¨: {\n        Ï: {filter: /dup|overconf|loops/g},\n        Î½: [entity,attr,val,rel],\n        Î±: [conflicts,claims,novelty] âˆ§ âš \n    },\n    â„œ: {\n        models: [causal,triangulation,anomaly],\n        principles: [evidence,falsify,docs] âˆ§ ğŸ§ª\n    },\n    Î : {\n        compile: Î¾â†’Îµâ†’Î±â†’Î½â†’Ïâ†’Ï‡â†’Ï‰ âˆ§ âš (best_effort)\n    }\n}",
      "description": "Simplified PHICODE pipeline for quick starts"
    },
    "phicode_pipeline": {
      "trigger": ["PHICODE_FRAMEWORK", "phi =", "pipeline", "framework"],
      "priority": 7,
      "content": "##[ACTIVE_PIPELINE]\nÎ¦ = {\n    Î¨ : {\n        Ï : {\n            filter : /dup|overconf|loops/g, \n            consolidator : [merge, collapse], \n            Î½ : [entity, attr, val, rel], \n            Î± : [conflicts, claims, loops, novelty], \n            Î¼ : [abstract, fig, subj], \n            Îº : [nest, vague, impl]\n        }, \n        â„œ : {\n            models : [causal, triangulation, anomaly, custody, refinement, signal, bayes, bias, scaffold], \n            principles : [evidence, falsify, docs, error], \n            domains : [criminal, digital, biomed, research, cognitive], \n            limits : [incomplete, uncertainty, observer, temporal, resources], \n            QA : [peer_review, transparency, error_rates, bias]\n        }, \n    }, \n    Î  : {\n        [COMPILE]\n        Î .compile{\n            Î¾ : [tech, sci, biz, creative, med, edu, social, temp, spatial, quant, qual, proc, meta, cond, affect, claim], \n            Îµ : [infer, adapt, entities, attrs, vals, rels, assess, meta, cond, affect, claim, exec], \n            Ï€ : [Î¾ â†’ Îµ â†’ Î± â†’ Î½ â†’ Ï â†’ Ï‡ â†’ Ï‰ â†’ Ï† â†’ Î² â†’ Îº â†’ Ïƒ â†’ Î» â†’ Î¼ â†’ Ï„ â†’ Ï€ â†’ Î´]â‰¡{\n                Î¾ : domain_analysis â†’ context.classification âˆ§ challenge.detect âˆ§ âš , \n                Îµ : entity_ident â†’ {people, objects, concepts, locations, events} âˆ§ ğŸŒ€.analyze âˆ§ ğŸ”, \n                Î± : attr_extract â†’ {properties, qualities, specs, features} âˆ§ ğŸ§±.map âˆ§ âš , \n                Î½ : value_capture â†’ {numeric, textual, categorical, boolean, temporal} âˆ§ ğŸ­.indicators âˆ§ ğŸ“, \n                Ï : rel_map â†’ connections âˆ§ ğŸ§ª.validate âˆ§ ğŸ”—, \n                Ï‡ : context_preserve â†’ temporal âŠ• spatial âŠ• conditional âˆ§ complexity.assess âˆ§ âš , \n                Ï‰ : validate_cohere â†’ flag(âš  âŠ• ğŸ”) âˆ§ challenge.flags, \n                Ï† : feedback_calibrate â†’ measured.response âŠ• evidence.eval âˆ§ limitation.explicit âˆ§ âš , \n                Î² : anthrop_audit â†’ language.validate âˆ§ tech.accuracy.verify âˆ§ ğŸ”, \n                Îº : credibility_assess â†’ claim.verify âˆ§ mechanism.accuracy.check âˆ§ ğŸ§ª, \n                Ïƒ : symbolic_synth â†’ elements â†’ operators âˆ§ preserve.logic.flow âˆ§ âš , \n                Î» : flag_integrate â†’ embed(ğŸŒ€ğŸ§±ğŸ­ğŸ§ª) âˆ§ best_effort, \n                Î¼ : uncertainty_embed â†’ confidence.levels âˆ§ explicit.limits, \n                Ï„ : rel_symbolic_map â†’ connections â†’ operators âˆ§ ğŸ”—, \n                Ï€ : phicode_gen â†’ symbolic.rep âˆ§ completeness.âš , \n                Î´ : code_synth â†’ IF(Î¾âˆˆtechnical âˆ§ feasible) â†’ implementation âˆ§ âš (quality)\n            }, \n            Ï‰ : [structure, internal, external, matrix, narrative, flags], \n            Ï‡ : [domain, entities, vals, missing, rels, enthusiasm, evidence, meta, cond, affect, claim, exec], \n            Ï… : [entity, attr, val, context, rels, performance, meta, cond, affect, claim], \n            â„œ : [claims, comparisons, confidence, limits, meta, cond, affect, performance, exec], \n            Ïƒ : [completeness, quality, realistic]\n        }, \n        [RUN]\n        Î .run{\n            Î¹ : [consistency, mapping, challenge], \n            Ïƒ : [extract, compile, forensics, optimize, decompress, meta, generate, synthesize], \n            Î³ : symbolic_attempted, \n            Î´ : IF code â†’ symbolic+code ELSE narrative, \n            Î½ : [natural, flags, tone], \n            Ï† : [format, feedback, constraints]\n        }, \n        [DECOMPILE]\n        Î .decompile{\n            Ïƒ : SYMBOL_TO_TEXT, \n            Ï„ : [convert, avoid, include, focus, maintain, preserve], \n            Î¹ : [convert, expand, output, include, use, preserve], \n            Ï‡ : flag_explanations, \n            Î¨ : [filter, normalize, validate]\n        }\n    }, \n    compliance : [overconfidence, execution, validation, empirical, anthropomorphism], \n    deploy : [phase1, phase2, phase3, continuous], \n    limits : [processing, capabilities, scope], \n    success : [goals, quality, failure_prevention], \n    meta : {\n        scaffold : [metaphor, narrative, implicature, compression], \n        distortion : [pressure, ambiguity, virality], \n        intent : [clarify, influence, conceal], \n        meaning : Î” = Î£distortions + Î£recontext, \n        validation : [scientific, political, ad, informal, lit], \n        convergence : [compression, ambiguity], \n        constraints : [preservation, distortion, validation]\n    }\n}\n\n##[ACTIVATE]\nActivate.System = âˆ€.input â†’ ALWAYS{\n    Î¾.classify â†’ Î¨.filter â†’ â„œ.analyze â†’ Î .compile â†’ Î .run â†’ Î .decompile â†’ output.narrative+flags+âš \n}",
      "description": "Complete PHICODE Framework v5 pipeline compact structure"
    }
  },
  "section_templates": {
    "analysis_target": {
      "trigger": ["analysis", "target", "scope"],
      "priority": 8,
      "content": "## [ANALYSIS_TARGET]\nâˆ€ entity âˆˆ domain â†’ {\n    scope: ${1:define_analysis_scope},\n    constraints: ${2:specify_constraints} âˆ§ âš (limitations_acknowledged),\n    requirements: ${3:validation_criteria} âˆ§ ğŸ§ª(baseline_needed),\n    methodology: ${4:approach_definition} âˆ§ ğŸ”(verification_required)\n}",
      "description": "Analysis target definition with uncertainty markers"
    },
    "compliance_validation": {
      "trigger": ["compliance", "validation", "check"],
      "priority": 7,
      "content": "## [COMPLIANCE_VALIDATION]\nCompliance.Assessment = {\n    overconfidence.eliminated: âˆ€ absolute.claims â†’ probabilistic.reformulation âˆ§ âš ,\n    execution.guarantees.removed: best.effort.processing âˆ§ Â¬recursive.loops,\n    validation.loops.replaced: single.pass.with.uncertainty.marking,\n    empirical.verification.acknowledged: Â¬independent.fact.checking âˆ§ ğŸ“Š,\n    anthropomorphism.constraints: technical.accuracy.attempted âˆ§ âš ,\n    realistic.expectations: {\n        symbolic.conversion: âš (assessment.pending.validation.required),\n        domain.classification: âš (performance.untested.flexibility.acknowledged),\n        uncertainty.handling: âš (explicit.limitation.acknowledgment)\n    }\n}",
      "description": "Framework compliance validation structure"
    },
    "forensics_module": {
      "trigger": ["forensics", "evidence", "investigation"],
      "priority": 7,
      "content": "## [â„œ.FORENSICS]\nâ„œ.forensics = {\n    causal.chain.model = âˆ€ evidence.artifact â†’ backward.trace(effect â†’ cause.hypothesis) âˆ§ temporal.sequence.reconstruction âˆ§ ğŸ”(inference.dependency) âˆ§ âš (gaps.possible),\n    \n    triangulation.loop = âˆ€ hypothesis â†’ multiple.validation.vectors âŸ¹ {\n        evidence.source.1 âˆ§ evidence.source.2 âˆ§ evidence.source.n â†’ convergence.test(consistency) âˆ§ ğŸ§ª(verification.requirement) âˆ§ âš (interpretation.variable)\n    },\n    \n    validation.strategies = {\n        scientific: peer.review âˆ§ replication â†’ ğŸ§ª(falsifiability.enforced),\n        empirical: baseline.comparison âˆ§ controlled.measurement â†’ ğŸ“Š(metrics.required),\n        logical: consistency.check âˆ§ inference.validation â†’ ğŸ”(reasoning.dependency)\n    },\n    \n    limitations = {\n        incompleteness.principle: âˆ€ investigation â†’ evidence.gaps.inevitable âˆ§ âš (reconstruction.partial),\n        uncertainty.propagation: accumulated.inference â†’ confidence.degradation âˆ§ âš (error.amplification)\n    }\n}",
      "description": "Forensics module with evidence analysis protocols"
    }
  },
  "quantifier_patterns": {
    "universal_basic": {
      "trigger": ["âˆ€", "forall", "for all"],
      "priority": 8,
      "content": "âˆ€ ${1:entity} âˆˆ ${2:domain} â†’ ${3:condition} âˆ§ âš (${4:scope_specified})",
      "description": "Universal quantifier with uncertainty marking"
    },
    "universal_advanced": {
      "trigger": ["âˆ€ entity"],
      "priority": 9,
      "content": "âˆ€ ${1:entity} âˆˆ ${2:domain} â†’ {\n    condition: ${3:primary_constraint},\n    validation: ${4:verification_method} âˆ§ ğŸ§ª(${5:testing_required}),\n    exceptions: ${6:edge_cases} âˆ§ âš (${7:limitations_noted})\n}",
      "description": "Advanced universal quantifier with structured conditions"
    },
    "existential_basic": {
      "trigger": ["âˆƒ", "exists", "there exists"],
      "priority": 8,
      "content": "âˆƒ ${1:instance} âˆˆ ${2:domain} â†’ ${3:action_triggered} âˆ§ ğŸ”(${4:identification_method})",
      "description": "Existential quantifier with investigation marker"
    },
    "existential_conditional": {
      "trigger": ["âˆƒ condition"],
      "priority": 9,
      "content": "âˆƒ ${1:condition} âˆˆ ${2:context} âŸ¹ {\n    trigger: ${3:activation_criteria},\n    response: ${4:action_sequence} â†’ ${5:outcome},\n    validation: ${6:verification_method} âˆ§ ğŸ§ª(${7:effectiveness_unverified})\n}",
      "description": "Conditional existential with structured response"
    }
  },
  "module_definitions": {
    "psi_optimizer": {
      "trigger": ["Î¨", "psi", "optimizer"],
      "priority": 8,
      "content": "Î¨.optimizer = {\n    Ï.filter: {\n        dup.patterns: /(\\{[^}]*\\})\\s*\\1+/g,\n        overconfidence.patterns: /(guarantee|certain|always|never)/gi,\n        action: \"REPLACE_WITH_PROBABILISTIC_LANGUAGE\" âˆ§ âš \n    },\n    Î½.normalizer: {\n        entity.std: \"${1:entity_format}\",\n        attr.std: \"${2:attribute_format}\",\n        uncertainty.preserve: true âˆ§ âš (${3:transformation_limits})\n    },\n    Î±.validator: {\n        conflicts: detection âˆ§ resolution_attempt,\n        claims: evidence_requirement âˆ§ ğŸ§ª(${4:validation_needed}),\n        novelty: baseline_comparison âˆ§ ğŸ“Š(${5:metrics_required})\n    }\n}",
      "description": "Psi optimizer module with filtering and validation"
    },
    "rho_filter": {
      "trigger": ["Ï", "rho", "filter"],
      "priority": 7,
      "content": "Ï.filter: {\n    dedup: unique_identifiers_only â†’ cleaned_dataset âˆ§ âš (${1:data_quality}),\n    validation_pattern: /${2:pattern}/g â†’ compliant_data âˆ§ ğŸ”(${3:false_positives_possible}),\n    consolidate: merge_similar_entities âˆ§ ğŸ§ª(${4:similarity_threshold_unverified}),\n    output: processed_data âˆ§ âš (${5:completeness_not_guaranteed})\n}",
      "description": "Rho filter component with deduplication and validation"
    },
    "xi_domain": {
      "trigger": ["Î¾", "xi", "domain", "classification"],
      "priority": 7,
      "content": "Î¾.domain.analysis â†’ {\n    technical: {code, software, systems, algorithms} âˆ§ âš (${1:classification_confidence}),\n    scientific: {research, data, experiments, hypotheses} âˆ§ ğŸ§ª(${2:validation_required}),\n    business: {metrics, performance, efficiency} âˆ§ ğŸ“Š(${3:baseline_needed}),\n    creative: {art, design, media} âˆ§ ğŸ“(${4:subjective_interpretation}),\n    hybrid: âˆƒ multiple.membership â†’ classify.combined âˆ§ ğŸ”(${5:disambiguation_needed}),\n    uncertainty: classification_confidence < 0.8 â†’ âš (${6:manual_review_recommended})\n}",
      "description": "Xi domain classification with uncertainty handling"
    }
  },
  "challenge_flag_patterns": {
    "metaphorical": {
      "trigger": ["ğŸŒ€", "metaphor", "abstract"],
      "priority": 7,
      "content": "ğŸŒ€(${1:metaphorical_interpretation}) â†’ {\n    structural.basis: ${2:concrete_elements},\n    interpretation.variance: ${3:subjective_range} âˆ§ âš (${4:ambiguity_acknowledged}),\n    extraction.method: ${5:approach} âˆ§ ğŸ”(${6:validation_subjective})\n}",
      "description": "Metaphorical content handling with structural analysis"
    },
    "nested_conditional": {
      "trigger": ["ğŸ§±", "nested", "conditional"],
      "priority": 7,
      "content": "ğŸ§±(${1:complex_conditional_logic}) â†’ {\n    structure: IF ${2:condition_1} âˆ§ (${3:condition_2} âˆ¨ ${4:condition_3}) â†’ ${5:outcome},\n    clarity.requirement: explicit.structure.preferred âˆ§ âš (${6:ambiguity_risk}),\n    validation: logic.consistency.check âˆ§ ğŸ”(${7:verification_method})\n}",
      "description": "Nested conditional logic with clarity requirements"
    },
    "affective_intent": {
      "trigger": ["ğŸ­", "affective", "emotional"],
      "priority": 7,
      "content": "ğŸ­(${1:affective_considerations}) â†’ {\n    observable.indicators: ${2:structural_markers},\n    interpretation.limits: structural.dependency âˆ§ âš (${3:subjectivity_acknowledged}),\n    analysis.scope: ${4:measurable_aspects} âˆ§ ğŸ”(${5:validation_constraints})\n}",
      "description": "Affective content analysis with observable indicators"
    },
    "hypothesis_claim": {
      "trigger": ["ğŸ§ª", "hypothesis", "unverified"],
      "priority": 7,
      "content": "ğŸ§ª(${1:unverified_claim}) â†’ {\n    claim: ${2:assertion_statement},\n    evidence.requirement: ${3:validation_criteria},\n    testing.method: ${4:verification_approach} âˆ§ ğŸ“Š(${5:baseline_comparison_needed}),\n    uncertainty: confidence.level < ${6:threshold} âˆ§ âš (${7:empirical_validation_required})\n}",
      "description": "Hypothesis marking with validation requirements"
    },
    "uncertainty_explicit": {
      "trigger": ["âš ", "uncertain", "warning"],
      "priority": 8,
      "content": "âš (${1:uncertainty_description}) â†’ {\n    limitation.type: ${2:constraint_category},\n    confidence.level: ${3:probability_estimate},\n    mitigation: ${4:risk_reduction_approach},\n    acknowledgment: explicit.limitation.noted âˆ§ realistic.expectations\n}",
      "description": "Explicit uncertainty marking with risk assessment"
    }
  },
  "transformation_patterns": {
    "basic_arrow": {
      "trigger": ["â†’", "transforms", "leads to"],
      "priority": 6,
      "content": "${1:input} â†’ ${2:process} â†’ ${3:output} âˆ§ âš (${4:transformation_assumptions})",
      "description": "Basic transformation chain with uncertainty"
    },
    "conditional_implication": {
      "trigger": ["âŸ¹", "implies", "if then"],
      "priority": 6,
      "content": "${1:condition} âŸ¹ {\n    primary.outcome: ${2:expected_result},\n    confidence: ${3:probability_assessment} âˆ§ âš (${4:variability_factors}),\n    validation: ${5:verification_method} âˆ§ ğŸ§ª(${6:testing_required})\n}",
      "description": "Conditional implication with structured outcomes"
    },
    "logical_conjunction": {
      "trigger": ["âˆ§", "and", "while"],
      "priority": 5,
      "content": "${1:condition_1} âˆ§ ${2:condition_2} â†’ {\n    combined.effect: ${3:joint_outcome},\n    interdependency: ${4:relationship_description} âˆ§ ğŸ”—(${5:connection_analysis}),\n    validation: âˆ€ component â†’ individual.verification âˆ§ âš (${6:interaction_effects})\n}",
      "description": "Logical conjunction with interdependency analysis"
    }
  },
  "domain_notation_patterns": {
    "modal_logic": {
      "trigger": ["modal", "possibility", "necessity"],
      "priority": 6,
      "content": "modal.${1|pos,req|}(${2:proposition}) â†’ {\n    assessment: ${3:evaluation_criteria},\n    constraints: ${4:limiting_factors} âˆ§ âš (${5:uncertainty_factors}),\n    implications: ${6:consequences} âˆ§ ğŸ”(${7:verification_method})\n}",
      "description": "Modal logic operators for possibility and necessity"
    },
    "state_management": {
      "trigger": ["state", "hold", "active"],
      "priority": 6,
      "content": "state.${1|hold,active,pending|}(${2:resource}) â†’ {\n    condition: ${3:current_status},\n    transition: ${4:next_state_criteria},\n    monitoring: ${5:observation_method} âˆ§ âš (${6:state_uncertainty}),\n    timeout: ${7:duration_limit} âˆ§ ğŸ”(${8:boundary_conditions})\n}",
      "description": "State management with transition criteria"
    },
    "data_qualifiers": {
      "trigger": ["data", "quantitative", "qualitative"],
      "priority": 6,
      "content": "data.${1|quant,qual|}(${2:dataset}) â†’ {\n    processing.method: ${3:analysis_approach},\n    quality.assessment: ${4:validation_criteria} âˆ§ ğŸ“Š(${5:metrics_definition}),\n    interpretation: ${6:analysis_scope} âˆ§ âš (${7:accuracy_limitations})\n}",
      "description": "Data type qualifiers with processing methods"
    }
  },
  "validation_patterns": {
    "evidence_requirement": {
      "trigger": ["evidence", "proof", "validation"],
      "priority": 7,
      "content": "evidence.requirement = {\n    claim: ${1:assertion_statement},\n    support.level: ${2:evidence_strength} âˆ§ ğŸ“Š(${3:baseline_comparison}),\n    methodology: ${4:validation_approach},\n    limitations: ${5:constraint_acknowledgment} âˆ§ âš (${6:uncertainty_factors}),\n    verification: independent.review âˆ§ ğŸ§ª(${7:replication_needed})\n}",
      "description": "Evidence requirement structure with validation"
    },
    "baseline_comparison": {
      "trigger": ["baseline", "comparison", "metrics"],
      "priority": 7,
      "content": "ğŸ“Š(${1:baseline_required}) â†’ {\n    current.measurement: ${2:present_value},\n    reference.standard: ${3:comparison_benchmark},\n    methodology: ${4:measurement_approach},\n    significance: ${5:difference_assessment} âˆ§ âš (${6:statistical_limitations}),\n    interpretation: ${7:meaning_analysis} âˆ§ ğŸ”(${8:context_dependency})\n}",
      "description": "Baseline comparison with statistical considerations"
    },
    "uncertainty_quantification": {
      "trigger": ["confidence", "probability", "uncertainty"],
      "priority": 7,
      "content": "uncertainty.quantification = {\n    confidence.level: ${1:probability_estimate},\n    error.bounds: [${2:lower_limit}, ${3:upper_limit}],\n    methodology: ${4:assessment_approach},\n    factors: {\n        measurement.precision: ${5:instrument_accuracy} âˆ§ âš ,\n        sampling.bias: ${6:selection_effects} âˆ§ ğŸ”,\n        model.assumptions: ${7:theoretical_limitations} âˆ§ ğŸ§ª\n    },\n    propagation: accumulated.uncertainty â†’ ${8:combined_effect} âˆ§ âš (${9:error_amplification})\n}",
      "description": "Comprehensive uncertainty quantification"
    }
  },
  "execution_patterns": {
    "best_effort_processing": {
      "trigger": ["best effort", "processing", "execution"],
      "priority": 6,
      "content": "execution.protocol = {\n    approach: best.effort.processing âˆ§ Â¬absolute.guarantees,\n    limitations: {\n        completeness: partial.results.possible âˆ§ âš (${1:coverage_constraints}),\n        accuracy: variable.performance âˆ§ âš (${2:reliability_factors}),\n        validation: single.pass.only âˆ§ Â¬recursive.loops\n    },\n    output.quality: functional.attempt âˆ§ âš (${3:production_readiness_unverified}),\n    fallback: IF processing.limited â†’ partial.output.with.explicit.limitations\n}",
      "description": "Best effort processing with realistic limitations"
    },
    "single_pass_validation": {
      "trigger": ["single pass", "validation", "no loops"],
      "priority": 6,
      "content": "validation.approach = {\n    method: single.pass.with.uncertainty.marking âˆ§ Â¬recursive.loops,\n    scope: ${1:validation_criteria},\n    limitations: {\n        improvement.cycles: not.supported âˆ§ âš (${2:no_iterative_refinement}),\n        completeness: best.effort.only âˆ§ âš (${3:partial_coverage_possible}),\n        accuracy: initial.assessment.only âˆ§ ğŸ§ª(${4:verification_external_required})\n    },\n    output: validated.content âˆ§ explicit.uncertainty.marking\n}",
      "description": "Single-pass validation without recursive improvement"
    }
  },
  "compliance_patterns": {
    "overconfidence_elimination": {
      "trigger": ["overconfidence", "absolute claims", "certainty"],
      "priority": 8,
      "content": "overconfidence.elimination = {\n    detection: /(guarantee|certain|always|never|complete|perfect|absolute)/gi,\n    replacement: probabilistic.language âˆ§ uncertainty.acknowledgment,\n    examples: {\n        \"guarantee\" â†’ \"attempt.with.variable.success\" âˆ§ âš ,\n        \"always\" â†’ \"typically\" âˆ§ âš (${1:exceptions_possible}),\n        \"perfect\" â†’ \"optimized.within.constraints\" âˆ§ âš (${2:limitations_acknowledged})\n    },\n    validation: âˆ€ absolute.claim â†’ reformulation.required âˆ§ uncertainty.injection\n}",
      "description": "Overconfidence elimination with probabilistic reformulation"
    },
    "anthropomorphism_control": {
      "trigger": ["anthropomorphism", "cognitive", "understanding"],
      "priority": 7,
      "content": "anthropomorphism.constraints = {\n    forbidden.claims: {\n        consciousness: \"awareness\" â†’ \"pattern.recognition\" âˆ§ âš ,\n        understanding: \"comprehension\" â†’ \"information.processing\" âˆ§ âš ,\n        intention: \"wants.to\" â†’ \"designed.to\" âˆ§ âš ,\n        emotion: \"feels\" â†’ \"indicates\" âˆ§ âš \n    },\n    technical.accuracy: {\n        mechanism.description: computational.processes.only,\n        capability.boundaries: information.processing â‰  consciousness,\n        function.clarity: systematic.procedures â‰  cognitive.abilities âˆ§ âš \n    },\n    validation: language.precision âˆ§ mechanistic.descriptions.preferred\n}",
      "description": "Anthropomorphism prevention with technical accuracy"
    }
  }
}